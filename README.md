    <h1>Image Captioning Project</h1>

<h2>Dependencies and Usage</h2>
<p>To run the project, the following dependencies are required:</p>
<ul>
    <li>Python 3.x</li>
    <li>TensorFlow</li>
    <li>Keras</li>
    <li>NumPy</li>
    <li>tqdm</li>
    <li>NLTK</li>
</ul>

<br>
<h2>To use the project, follow these steps:</h2>
<ul>
    <li>Prepare the dataset with images and captions.</li>
    <li>Set up the environment with the required dependencies.</li>
    <li>Run the provided code to preprocess the data, train the model, and generate captions.</li>
    <li>Evaluate the generated captions using appropriate metrics.</li>
    <li>Customize the project according to your needs and experiment with different architectures or datasets.</li>
    
</ul>

<br>
<h2>Acknowledgments</h2>
<p>This project is built upon various open-source libraries, datasets, and research papers. The following resources were used in the development of this project:</p>
<ul>
    <li>Flickr8k Dataset</li>
    <li>VGG16 Model</li>
    <li>TensorFlow and Keras libraries</li>
    <li>NLTK library</li>
</ul>
